{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 29781,
     "databundleVersionId": 2887556,
     "sourceType": "competition"
    },
    {
     "sourceId": 2484624,
     "sourceType": "datasetVersion",
     "datasetId": 1169793
    }
   ],
   "dockerImageVersionId": 31153,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "agricultural-operations",
   "cell_type": "markdown",
   "source": [
    "# Введение #\n",
    "\n",
    "В уроках 2 и 3 мы рассматривали прогнозирование как простую задачу регрессии, где все признаки получаются из одного входа — временного индекса. Мы могли легко строить прогнозы на любой момент в будущем, просто генерируя нужные признаки тренда и сезонности.\n",
    "\n",
    "Однако когда мы добавили лаговые признаки в уроке 4, характер задачи изменился. Лаговые признаки требуют, чтобы лагированное значение цели было известно на момент прогноза. Лаг 1 сдвигает ряд вперёд на 1 шаг, что означает: можно прогнозировать на 1 шаг вперёд, но не на 2.\n",
    "\n",
    "В уроке 4 мы просто предполагали, что всегда можем сгенерировать лаги на нужный период прогноза (то есть каждый прогноз был на один шаг вперёд). В реальном прогнозировании обычно требуется больше, поэтому в этом уроке мы научимся строить прогнозы для разных ситуаций.\n",
    "\n",
    "# Определение задачи прогнозирования #\n",
    "\n",
    "Перед тем как проектировать модель прогнозирования, нужно определить две вещи:\n",
    "- какая информация доступна на момент прогноза (признаки), и\n",
    "- на какой период времени нужны прогнозные значения (цель).\n",
    "\n",
    "**Forecast origin** — момент времени, в который мы делаем прогноз. На практике его можно считать последним моментом, для которого есть обучающие данные для прогнозируемого ряда. Всё до origin можно использовать для создания признаков.\n",
    "\n",
    "**Forecast horizon** — период времени, для которого мы делаем прогноз. Часто горизонт описывают количеством шагов: «прогноз на 1 шаг» или «на 5 шагов», например. Горизонт определяет цель.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/xwEgcOk.png\" width=500, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Трёхшаговый горизонт прогноза с двухшаговым опережением (lead time) и четырьмя лаговыми признаками. Рисунок показывает одну строку обучающих данных — то есть данные для одного прогноза.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Период между origin и horizon — это **lead time** (иногда *latency*) прогноза. Lead time описывается числом шагов от origin до горизонта: «прогноз на 1 шаг вперёд» или «на 3 шага вперёд», например. На практике прогноз может начинаться через несколько шагов после origin из‑за задержек в получении или обработке данных.\n",
    "\n",
    "# Подготовка данных для прогнозирования #\n",
    "\n",
    "Чтобы прогнозировать временные ряды с помощью ML‑алгоритмов, нужно преобразовать ряд в датафрейм, который можно использовать с этими алгоритмами. (Если, конечно, вы не используете только детерминированные признаки вроде тренда и сезонности.)\n",
    "\n",
    "Первую половину этого процесса мы увидели в уроке 4, когда создавали набор признаков из лагов. Вторая половина — подготовка цели. Способ зависит от задачи прогнозирования.\n",
    "\n",
    "Каждая строка в датафрейме представляет один прогноз. Временной индекс строки — это первый момент горизонта прогноза, но значения всего горизонта размещаются в той же строке. Для многшаговых прогнозов это означает, что модель должна выдавать несколько выходов — по одному на каждый шаг.\n"
   ],
   "metadata": {}
  },
  {
   "id": "negative-fantasy",
   "cell_type": "code",
   "source": "\nimport numpy as np\nimport pandas as pd\n\nN = 20\nts = pd.Series(\n    np.arange(N),\n    index=pd.period_range(start='2010', freq='A', periods=N, name='Year'),\n    dtype=pd.Int8Dtype,\n)\n\n# Lag features\nX = pd.DataFrame({\n    'y_lag_2': ts.shift(2),\n    'y_lag_3': ts.shift(3),\n    'y_lag_4': ts.shift(4),\n    'y_lag_5': ts.shift(5),\n    'y_lag_6': ts.shift(6),    \n})\n\n# Multistep targets\ny = pd.DataFrame({\n    'y_step_3': ts.shift(-2),\n    'y_step_2': ts.shift(-1),\n    'y_step_1': ts,\n})\n\ndata = pd.concat({'Targets': y, 'Features': X}, axis=1)\n\ndata.head(10).style.set_properties(['Targets'], **{'background-color': 'LavenderBlush'}) \\\n                   .set_properties(['Features'], **{'background-color': 'Lavender'})",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "pretty-literature",
   "cell_type": "markdown",
   "source": [
    "Выше показано, как был бы подготовлен набор данных, аналогичный рисунку *Defining a Forecast*: трёхшаговая задача прогнозирования с двухшаговым lead time и пятью лаговыми признаками. Исходный временной ряд — `y_step_1`. Пропущенные значения можно либо заполнить, либо удалить."
   ],
   "metadata": {}
  },
  {
   "id": "adaptive-counter",
   "cell_type": "code",
   "source": "\nfrom pathlib import Path\nfrom warnings import simplefilter\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\n\nsimplefilter(\"ignore\")\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 4))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n)\n%config InlineBackend.figure_format = 'retina'\n\n\ndef plot_multistep(y, every=1, ax=None, palette_kwargs=None):\n    palette_kwargs_ = dict(palette='husl', n_colors=16, desat=None)\n    if palette_kwargs is not None:\n        palette_kwargs_.update(palette_kwargs)\n    palette = sns.color_palette(**palette_kwargs_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    ax.set_prop_cycle(plt.cycler('color', palette))\n    for date, preds in y[::every].iterrows():\n        preds.index = pd.period_range(start=date, periods=len(preds))\n        preds.plot(ax=ax)\n    return ax\n\n\ndata_dir = Path(\"../input/ts-course-data\")\nflu_trends = pd.read_csv(data_dir / \"flu-trends.csv\")\nflu_trends.set_index(\n    pd.PeriodIndex(flu_trends.Week, freq=\"W\"),\n    inplace=True,\n)\nflu_trends.drop(\"Week\", axis=1, inplace=True)",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "sustained-exception",
   "cell_type": "markdown",
   "source": [
    "# Стратегии многшагового прогнозирования #\n",
    "\n",
    "Существует несколько стратегий для получения нескольких целевых шагов, требуемых прогнозом. Мы рассмотрим четыре распространённые стратегии, каждая со своими плюсами и минусами.\n",
    "\n",
    "### Multioutput‑модель\n",
    "\n",
    "Используйте модель, которая естественным образом выдаёт несколько выходов. Линейная регрессия и нейросети умеют это делать. Стратегия простая и эффективная, но доступна не для всех алгоритмов (например, XGBoost так не умеет).\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/uFsHiqr.png\" width=300, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "### Direct‑стратегия\n",
    "\n",
    "Обучите отдельную модель для каждого шага горизонта: одна модель прогнозирует на 1 шаг вперёд, другая — на 2 шага и т. д. Прогноз на 1 шаг — другая задача, чем на 2 шага (и т. д.), поэтому полезно иметь отдельную модель для каждого шага. Минус — обучение большого числа моделей может быть вычислительно дорогим.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/HkolNMV.png\" width=900, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "### Recursive‑стратегия\n",
    "\n",
    "Обучите одну одношаговую модель и используйте её прогнозы для обновления лаговых признаков на следующий шаг. В рекурсивном подходе мы подаём 1‑шаговый прогноз обратно в ту же модель как лаг для следующего шага. Нужна всего одна модель, но ошибки будут накапливаться по шагам, поэтому прогнозы для длинных горизонтов могут быть неточными.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/sqkSFDn.png\" width=300, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "### DirRec‑стратегия\n",
    "\n",
    "Комбинация Direct и Recursive: обучаем модель для каждого шага и используем прогнозы предыдущих шагов как *новые* лаговые признаки. Шаг за шагом каждая модель получает дополнительный лаговый вход. Поскольку у каждой модели всегда актуальные лаги, DirRec может лучше захватывать последовательную зависимость, чем Direct, но, как и Recursive, может страдать от накопления ошибок.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/B7KAvAO.png\" width=900, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "# Пример — Flu Trends #\n",
    "\n",
    "В этом примере мы применим стратегии MultiOutput и Direct к данным *Flu Trends* из урока 4, но теперь будем строить реальные прогнозы на несколько недель вперёд относительно обучающего периода.\n",
    "\n",
    "Определим задачу прогнозирования: горизонт 8 недель и lead time 1 неделя. Иными словами, мы прогнозируем восемь недель случаев гриппа, начиная со следующей недели.\n",
    "\n",
    "Скрытая ячейка настраивает пример и определяет вспомогательную функцию `plot_multistep`."
   ],
   "metadata": {}
  },
  {
   "id": "collect-granny",
   "cell_type": "code",
   "source": "def make_lags(ts, lags, lead_time=1):\n    return pd.concat(\n        {\n            f'y_lag_{i}': ts.shift(i)\n            for i in range(lead_time, lags + lead_time)\n        },\n        axis=1)\n\n\n# Four weeks of lag features\ny = flu_trends.FluVisits.copy()\nX = make_lags(y, lags=4).fillna(0.0)\n\n\ndef make_multistep_target(ts, steps):\n    return pd.concat(\n        {f'y_step_{i + 1}': ts.shift(-i)\n         for i in range(steps)},\n        axis=1)\n\n\n# Eight-week forecast\ny = make_multistep_target(y, steps=8).dropna()\n\n# Shifting has created indexes that don't match. Only keep times for\n# which we have both targets and features.\ny, X = y.align(X, join='inner', axis=0)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "separated-stranger",
   "cell_type": "markdown",
   "source": [
    "Сначала подготовим наш целевой ряд (еженедельные визиты к врачу по поводу гриппа) для многшагового прогнозирования. После этого обучение и прогнозирование будут очень прямолинейными."
   ],
   "metadata": {}
  },
  {
   "id": "loaded-worship",
   "cell_type": "code",
   "source": "\n# Create splits\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=y.columns)\ny_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "modular-astronomy",
   "cell_type": "markdown",
   "source": [
    "### Multioutput‑модель\n",
    "\n",
    "Используем линейную регрессию как стратегию MultiOutput. После подготовки данных для нескольких выходов обучение и прогнозирование идут как обычно."
   ],
   "metadata": {}
  },
  {
   "id": "happy-inspector",
   "cell_type": "code",
   "source": "\ntrain_rmse = mean_squared_error(y_train, y_fit, squared=False)\ntest_rmse = mean_squared_error(y_test, y_pred, squared=False)\nprint((f\"Train RMSE: {train_rmse:.2f}\\n\" f\"Test RMSE: {test_rmse:.2f}\"))\n\npalette = dict(palette='husl', n_colors=64)\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6))\nax1 = flu_trends.FluVisits[y_fit.index].plot(**plot_params, ax=ax1)\nax1 = plot_multistep(y_fit, ax=ax1, palette_kwargs=palette)\n_ = ax1.legend(['FluVisits (train)', 'Forecast'])\nax2 = flu_trends.FluVisits[y_pred.index].plot(**plot_params, ax=ax2)\nax2 = plot_multistep(y_pred, ax=ax2, palette_kwargs=palette)\n_ = ax2.legend(['FluVisits (test)', 'Forecast'])",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "representative-ability",
   "cell_type": "markdown",
   "source": [
    "Помните, что многшаговая модель выдаёт полный прогноз для каждого примера, используемого на вход. В обучающем наборе 269 недель, в тестовом — 90 недель, и теперь для каждой из этих недель у нас есть 8‑шаговый прогноз."
   ],
   "metadata": {}
  },
  {
   "id": "adaptive-colonial",
   "cell_type": "code",
   "source": "from sklearn.multioutput import MultiOutputRegressor\n\nmodel = MultiOutputRegressor(XGBRegressor())\nmodel.fit(X_train, y_train)\n\ny_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=y.columns)\ny_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "several-marble",
   "cell_type": "markdown",
   "source": [
    "### Direct‑стратегия\n",
    "\n",
    "XGBoost не умеет выдавать несколько выходов в задачах регрессии. Но применив стратегию Direct, мы всё равно можем использовать его для многшаговых прогнозов. Это так же просто, как обернуть его в `MultiOutputRegressor` из scikit‑learn."
   ],
   "metadata": {}
  },
  {
   "id": "frequent-reservation",
   "cell_type": "code",
   "source": "\ntrain_rmse = mean_squared_error(y_train, y_fit, squared=False)\ntest_rmse = mean_squared_error(y_test, y_pred, squared=False)\nprint((f\"Train RMSE: {train_rmse:.2f}\\n\" f\"Test RMSE: {test_rmse:.2f}\"))\n\npalette = dict(palette='husl', n_colors=64)\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6))\nax1 = flu_trends.FluVisits[y_fit.index].plot(**plot_params, ax=ax1)\nax1 = plot_multistep(y_fit, ax=ax1, palette_kwargs=palette)\n_ = ax1.legend(['FluVisits (train)', 'Forecast'])\nax2 = flu_trends.FluVisits[y_pred.index].plot(**plot_params, ax=ax2)\nax2 = plot_multistep(y_pred, ax=ax2, palette_kwargs=palette)\n_ = ax2.legend(['FluVisits (test)', 'Forecast'])",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "illegal-kidney",
   "cell_type": "markdown",
   "source": [
    "Здесь XGBoost явно переобучается на обучающем наборе. Но на тесте он, похоже, смог уловить часть динамики сезона гриппа лучше, чем линейная регрессия. Вероятно, с подбором гиперпараметров он будет ещё лучше.\n",
    "\n",
    "Чтобы использовать стратегию DirRec, достаточно заменить `MultiOutputRegressor` на другой обёрточный класс scikit‑learn — `RegressorChain`. Стратегию Recursive нам нужно было бы реализовать самостоятельно.\n",
    "\n",
    "# Ваш ход #\n",
    "\n",
    "[**Создайте датасет для прогнозирования**](https://www.kaggle.com/kernels/fork/20667477) для *Store Sales* и примените стратегию DirRec."
   ],
   "metadata": {}
  },
  {
   "id": "000b13f9",
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Есть вопросы или комментарии? Посетите [форум обсуждений курса](https://www.kaggle.com/learn/time-series/discussion), чтобы пообщаться с другими учащимися.*"
   ],
   "metadata": {}
  }
 ]
}