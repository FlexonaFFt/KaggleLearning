{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "papermill": {
   "duration": 5.170879,
   "end_time": "2020-12-23T18:50:12.376269",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-23T18:50:07.20539",
   "version": "2.1.0"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Введение\n",
    "\n",
    "Перед выбором данных и обучением моделей важно тщательно продумать, какие человеческие потребности должна обслуживать система ИИ - и стоит ли ее вообще создавать.\n",
    "\n",
    "**Дизайн, ориентированный на человека (HCD)** - это подход к проектированию систем, которые служат потребностям людей.\n",
    "\n",
    "В этом уроке вы узнаете, как применять HCD к системам ИИ. Затем вы проверите свои знания в **[упражнении](https://www.kaggle.com/kernels/fork/15577437)**, применив HCD к вопросам дизайна в интересных сценариях из реального мира.\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.006017,
     "end_time": "2020-12-23T18:50:12.210661",
     "exception": false,
     "start_time": "2020-12-23T18:50:12.204644",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Подход\n",
    "\n",
    "HCD вовлекает людей на каждом шаге процесса проектирования. Ваша команда должна как можно раньше принять подход HCD к ИИ - в идеале с момента, когда вы только начинаете рассматривать возможность создания системы ИИ.\n",
    "\n",
    "Следующие шесть шагов призваны помочь вам начать применять HCD к проектированию систем ИИ. При этом то, что HCD означает именно для вас, будет зависеть от вашей отрасли, ресурсов, организации и людей, которым вы хотите служить.\n",
    "\n",
    "\n",
    "## 1. Поймите потребности людей, чтобы определить проблему\n",
    "Работа с людьми для понимания болевых точек в их текущих процессах помогает выявить неудовлетворенные потребности. Это можно делать, наблюдая за тем, как люди пользуются существующими инструментами, проводя интервью, собирая фокус-группы, читая отзывы пользователей и другими способами. В этом шаге должна участвовать вся команда - включая дата-сайентистов и инженеров - чтобы каждый участник понял людей, которым вы надеетесь помочь. В команду следует включать и вовлекать людей с разными взглядами и опытом, в том числе по признакам расы, пола и другим характеристикам. Уточняйте формулировку проблемы и вместе генерируйте креативные и инклюзивные решения.\n",
    "\n",
    "> Компания хочет решить проблему ошибок дозировки иммунодепрессантов, которые назначаются пациентам после пересадки печени. Компания начинает с наблюдения за врачами, медсестрами и другим персоналом больницы на протяжении всего процесса трансплантации печени. Также она проводит интервью о текущем процессе определения дозировки - который опирается на опубликованные рекомендации и человеческое суждение - и делится видеоклипами из интервью со всей командой разработки. Компания также изучает исследования и собирает фокус-группы бывших пациентов и их семей. Все участники команды участвуют в свободном мозговом штурме возможных решений.\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.004456,
     "end_time": "2020-12-23T18:50:12.219862",
     "exception": false,
     "start_time": "2020-12-23T18:50:12.215406",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Спросите себя, добавляет ли ИИ ценность любому потенциальному решению\n",
    "\n",
    "Когда вы ясно понимаете, какую потребность вы решаете и как, подумайте, добавляет ли ИИ ценность.\n",
    " \n",
    "- Согласятся ли люди в целом, что результат, которого вы хотите достичь, является хорошим?\n",
    "- Будут ли не-ИИ системы - например решения на правилах, которые проще создавать, аудировать и поддерживать - значительно менее эффективными, чем система ИИ?\n",
    "- Используете ли вы ИИ для задачи, которую люди посчитали бы скучной, повторяющейся или иным образом требующей высокой концентрации?\n",
    "- Доказали ли решения на основе ИИ в прошлом, что они лучше других решений для подобных кейсов?\n",
    "\n",
    "Если вы ответили \"нет\" на любой из этих вопросов, решение на основе ИИ может быть ненужным или неуместным.\n",
    "\n",
    "> Агентство по реагированию на чрезвычайные ситуации работает с первыми реагирующими службами, чтобы сократить время спасения людей при бедствиях, например наводнениях. Трудоемкий и затратный по времени человеческий просмотр фото с дронов и спутников, чтобы находить людей, увеличивает время спасения. Все согласны, что ускорение просмотра фото - хороший результат, так как более быстрые спасения могут сохранить больше жизней. Агентство определяет, что система распознавания изображений на основе ИИ, вероятно, будет эффективнее, чем не-ИИ автоматизированная система для этой задачи. Оно также знает, что инструменты распознавания изображений на основе ИИ успешно применялись для просмотра аэросъемки в других отраслях, например в сельском хозяйстве. Поэтому агентство решает дальше изучить возможность решения на основе ИИ.\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.005854,
     "end_time": "2020-12-23T18:50:12.230199",
     "exception": false,
     "start_time": "2020-12-23T18:50:12.224345",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Рассмотрите потенциальный вред, который может причинить система ИИ\n",
    "\n",
    "Сопоставляйте преимущества использования ИИ с потенциальным вредом на протяжении всего конвейера проектирования: от сбора и разметки данных, до обучения модели и развертывания системы ИИ. Учитывайте влияние на пользователей и на общество. Ваша команда по приватности может помочь выявить скрытые проблемы конфиденциальности и определить, уместны ли методы сохранения приватности, такие как [дифференциальная приватность](https://developers.googleblog.com/2019/09/enabling-developers-and-organizations.html) или [федеративное обучение](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html). Предпринимайте шаги для уменьшения вреда, в том числе более эффективно встраивая людей - и, следовательно, человеческое суждение - в отбор данных, обучение модели и работу системы. Если вы оцениваете, что вред, вероятно, перевесит пользу, не создавайте систему.\n",
    "\n",
    "> Компания онлайн-образования хочет использовать систему ИИ, чтобы \"читать\" и автоматически выставлять оценки за эссе студентов, при этом перенаправляя сотрудников компании на повторную проверку случайных эссе и на просмотр эссе, с которыми система ИИ испытывает трудности. Система позволила бы компании быстро возвращать оценки студентам. Компания создает комитет по оценке вреда, который рекомендует систему не строить. Среди основных рисков, отмеченных комитетом: возможность того, что система ИИ воспримет предвзятость в отношении определенных языковых паттернов из обучающих данных и усилит ее (вредя людям из групп, которые используют такие языковые паттерны), стимулирование студентов \"обманывать\" алгоритм вместо улучшения своих эссе, а также снижение роли экспертов в образовании при увеличении роли технологических специалистов.\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.004235,
     "end_time": "2020-12-23T18:50:12.238904",
     "exception": false,
     "start_time": "2020-12-23T18:50:12.234669",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Прототипируйте, начиная с решений без ИИ\n",
    "\n",
    "Быстро разработайте не-ИИ прототип вашей системы ИИ, чтобы увидеть, как люди с ней взаимодействуют. Это делает прототипирование проще, быстрее и дешевле. Оно также дает вам раннюю информацию о том, чего пользователи ожидают от вашей системы, и как сделать их взаимодействие более полезным и осмысленным.\n",
    " \n",
    "Спроектируйте пользовательский интерфейс прототипа так, чтобы людям было легко понять, как работает ваша система, переключать настройки и предоставлять обратную связь.\n",
    " \n",
    "Люди, которые дают обратную связь, должны иметь разный опыт - в том числе по признакам расы, пола, экспертизы и другим характеристикам. Они также должны понимать и соглашаться с тем, в чем они помогают и как.\n",
    "\n",
    "> Стартап по стримингу фильмов хочет использовать ИИ для рекомендаций фильмов пользователям на основе их заявленных предпочтений и истории просмотров. Команда сначала приглашает разнообразную группу пользователей поделиться своими предпочтениями и историей просмотров с энтузиастом кино, который затем рекомендует фильмы, которые могут им понравиться. На основе этих разговоров и отзывов о том, какие фильмы понравились пользователям, команда меняет подход к категоризации фильмов. Раннее получение обратной связи от разнообразной группы пользователей и частые итерации позволяют команде улучшить продукт на ранней стадии, а не вносить дорогие исправления позже.\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.004302,
     "end_time": "2020-12-23T18:50:12.247708",
     "exception": false,
     "start_time": "2020-12-23T18:50:12.243406",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Предусмотрите способы оспорить систему\n",
    "\n",
    "Люди, которые используют вашу систему ИИ после ее запуска, должны иметь возможность оспорить ее рекомендации или легко отказаться от использования. Создайте системы и инструменты для приема, мониторинга и обработки таких обращений.\n",
    " \n",
    "Поговорите с пользователями и подумайте с точки зрения пользователя: если вам любопытны или не нравятся рекомендации системы, захотите ли вы оспорить их, например:\n",
    "- Запросив объяснение того, как она пришла к рекомендации?\n",
    "- Запросив изменение введенной вами информации?\n",
    "- Отключив некоторые функции?\n",
    "- Обратившись к продуктовой команде в соцсетях?\n",
    "- Предприняв какое-то другое действие?\n",
    " \n",
    "> Онлайн-компания видеоконференций использует ИИ для автоматического размытия фона во время видеозвонков. Компания успешно протестировала продукт с разнообразной группой людей разных этнических групп. Тем не менее она знает, что могут быть случаи, когда видео не будет правильно фокусироваться на лице человека. Поэтому она делает функцию размытия фона необязательной и добавляет кнопку для сообщения о проблемах. Компания также создает службу поддержки, чтобы отслеживать жалобы пользователей в социальных сетях и на других онлайн-форумах.\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.004125,
     "end_time": "2020-12-23T18:50:12.256199",
     "exception": false,
     "start_time": "2020-12-23T18:50:12.252074",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Встраивайте меры безопасности\n",
    "\n",
    "Меры безопасности защищают пользователей от вреда. Они стремятся ограничить непреднамеренное поведение и инциденты, обеспечивая надежное предоставление системой результатов высокого качества. Это возможно только благодаря обширной и непрерывной оценке и тестированию. Спроектируйте процессы вокруг вашей системы ИИ так, чтобы постоянно отслеживать производительность, доставку запланированных преимуществ, снижение вреда, метрики справедливости и любые изменения в том, как люди _на самом деле_ ее используют.\n",
    " \n",
    "Тип необходимых мер безопасности зависит от назначения системы и типов вреда, который она может причинить. Начните с обзора списка мер безопасности, встроенных в аналогичные не-ИИ продукты или сервисы. Затем пересмотрите ваш предыдущий анализ потенциального вреда от использования ИИ в системе (см. Шаг 3).\n",
    " \n",
    "Человеческий надзор за вашей системой ИИ крайне важен:\n",
    "- Создайте человеческую \"красную команду\", которая будет играть роль человека, пытающегося склонить вашу систему к непреднамеренному поведению. Затем укрепите систему против любой такой манипуляции.\n",
    "- Определите, как люди в вашей организации могут лучше всего мониторить безопасность системы после запуска.\n",
    "- Изучите способы, с помощью которых ваша система ИИ сможет быстро уведомлять человека, когда сталкивается со сложным случаем.\n",
    "- Создайте способы, чтобы пользователи и другие могли отмечать потенциальные проблемы безопасности.\n",
    " \n",
    "> Чтобы усилить безопасность своего продукта, компания, которая разрабатывает широко используемого голосового помощника с поддержкой ИИ, создает постоянную внутреннюю \"красную команду\", играющую роль злоумышленников, желающих манипулировать голосовым помощником. Красная команда разрабатывает атакующие входные данные, чтобы обмануть помощника. Затем компания использует обучение на состязательных примерах (adversarial training), чтобы защитить продукт от подобных атакующих входных данных, повышая его безопасность.\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.004172,
     "end_time": "2020-12-23T18:50:12.264808",
     "exception": false,
     "start_time": "2020-12-23T18:50:12.260636",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Узнать больше\n",
    "\n",
    "Чтобы глубже погрузиться в применение HCD к ИИ, ознакомьтесь с ресурсами:\n",
    "\n",
    "* [Вводная лекция](https://www.youtube.com/watch?v=bmjamLZ3v8A) Лекса Фридмана о человеко-ориентированном искусственном интеллекте\n",
    "* [Руководство](https://pair.withgoogle.com/guidebook/) Google People + AI Research (PAIR)\n",
    "* [Исследования](https://hai.stanford.edu/research) Stanford Human-Centered Artificial Intelligence (HAI)\n",
    "\n",
    "# Ваша очередь\n",
    "В упражнении вы будете **[использовать HCD для навигации по вопросам](https://www.kaggle.com/kernels/fork/15577437)** в сценариях проектирования систем ИИ.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Есть вопросы или комментарии? Посетите [форум обсуждения курса](https://www.kaggle.com/learn/ai-ethics/discussion), чтобы пообщаться с другими учащимися.*\n"
   ],
   "metadata": {}
  }
 ]
}